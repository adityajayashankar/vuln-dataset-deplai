"""
crawl_exploitdb.py
------------------
Downloads Exploit-DB's full exploit/shellcode CSV exports.
This is FAR better than scraping individual Exploit-DB pages because:
  - One download gets the entire database (70k+ exploits)
  - Official export â€” structured, clean, no scraping needed
  - Updated daily at https://gitlab.com/exploit-database/exploitdb
  - Includes: exploit code, CVE cross-references, platform, author, date

Output: raw_exploitdb.json

Alternative (if CSV not available): clones the Exploit-DB GitLab repo.
"""

import requests
import json
import csv
import re
import time
import subprocess
import tempfile
import os
from pathlib import Path
from io import StringIO
from tqdm import tqdm

# â”€â”€ Exploit-DB official CSV exports â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EXPLOITDB_FILES_CSV    = "https://gitlab.com/exploit-database/exploitdb/-/raw/main/files_exploits.csv"
EXPLOITDB_SHELLCODES_CSV = "https://gitlab.com/exploit-database/exploitdb/-/raw/main/files_shellcodes.csv"
EXPLOITDB_RAW_BASE     = "https://gitlab.com/exploit-database/exploitdb/-/raw/main/exploits"


def download_exploitdb_csv(url: str, label: str) -> list[dict]:
    """
    Download and parse an Exploit-DB CSV file.
    CSV columns: id, file, description, date_published, author, type,
                 platform, port, date_added, date_updated, verified, codes, tags
    'codes' column contains CVE IDs (semicolon-separated).
    """
    print(f"Downloading Exploit-DB {label} CSV...")
    try:
        resp = requests.get(url, timeout=60)
        resp.raise_for_status()

        reader  = csv.DictReader(StringIO(resp.text))
        records = []

        for row in reader:
            # 'codes' field contains CVE IDs like "CVE-2021-44228;CVE-2021-45046"
            codes_raw = row.get("codes", "")
            cves      = [c.strip() for c in codes_raw.split(";") if c.strip().startswith("CVE-")]

            # Also regex-scan description for CVE mentions
            desc = row.get("description", "")
            cves_in_desc = list(set(re.findall(r"CVE-\d{4}-\d+", desc, re.IGNORECASE)))
            cves = list(set(cves + cves_in_desc))

            records.append({
                "source":          "exploit_db",
                "exploit_id":      row.get("id", ""),
                "file_path":       row.get("file", ""),
                "description":     desc,
                "date_published":  row.get("date_published", ""),
                "author":          row.get("author", ""),
                "exploit_type":    row.get("type", ""),
                "platform":        row.get("platform", ""),
                "verified":        row.get("verified", "0") == "1",
                "tags":            row.get("tags", ""),
                "cves_mentioned":  cves
            })

        print(f"  âœ… Exploit-DB {label}: {len(records)} entries ({sum(1 for r in records if r['cves_mentioned'])} with CVEs)")
        return records

    except Exception as e:
        print(f"  âš ï¸  Exploit-DB {label} download failed: {e}")
        return []


def fetch_exploit_content(exploit_id: str, file_path: str, max_chars: int = 3000) -> str:
    """
    Fetch the actual exploit code/content from GitLab raw.
    Only fetches for verified exploits to save bandwidth.
    """
    if not file_path:
        return ""

    # file_path looks like: exploits/linux/remote/12345.py
    raw_url = f"https://gitlab.com/exploit-database/exploitdb/-/raw/main/{file_path}"
    try:
        resp = requests.get(raw_url, timeout=15)
        if resp.status_code == 200:
            return resp.text[:max_chars]
        return ""
    except Exception:
        return ""


def enrich_verified_exploits(records: list[dict], max_to_fetch: int = 50) -> list[dict]:
    """
    For verified exploits that map to CVEs, fetch the actual exploit content.
    This provides real payload/technique data for training.
    Only processes verified exploits to focus on quality.
    """
    verified_with_cves = [
        r for r in records
        if r.get("verified") and r.get("cves_mentioned") and r.get("file_path")
    ]

    print(f"\nEnriching {min(len(verified_with_cves), max_to_fetch)} verified exploits with code content...")

    enriched_count = 0
    for record in verified_with_cves[:max_to_fetch]:
        content = fetch_exploit_content(record["exploit_id"], record["file_path"])
        if content:
            record["exploit_content"] = content
            record["exploit_enriched"] = True
            enriched_count += 1
        time.sleep(0.3)  # Rate limit

    print(f"  âœ… Enriched {enriched_count} exploits with code content")
    return records


def run(out: str = "data/raw_exploitdb.json", enrich: bool = True):
    all_records: list[dict] = []

    # Download exploits CSV
    exploit_records = download_exploitdb_csv(EXPLOITDB_FILES_CSV, "exploits")
    all_records.extend(exploit_records)

    # Download shellcodes CSV
    shellcode_records = download_exploitdb_csv(EXPLOITDB_SHELLCODES_CSV, "shellcodes")
    all_records.extend(shellcode_records)

    # Optionally fetch exploit code for top verified records
    if enrich:
        all_records = enrich_verified_exploits(all_records, max_to_fetch=100)

    # Stats
    with_cves      = [r for r in all_records if r.get("cves_mentioned")]
    verified_count = sum(1 for r in all_records if r.get("verified"))
    platforms      = list(set(r.get("platform", "") for r in all_records if r.get("platform")))

    print(f"\nðŸ“Š Exploit-DB Summary:")
    print(f"  Total records:            {len(all_records)}")
    print(f"  Records with CVE mapping: {len(with_cves)}")
    print(f"  Verified exploits:        {verified_count}")
    print(f"  Platforms covered:        {len(platforms)}")

    with open(out, "w", encoding="utf-8") as f:
        json.dump(all_records, f, indent=2, ensure_ascii=False)

    print(f"\nâœ… Saved {len(all_records)} Exploit-DB records â†’ {out}")


if __name__ == "__main__":
    run()